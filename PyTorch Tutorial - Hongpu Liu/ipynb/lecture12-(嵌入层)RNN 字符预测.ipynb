{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN å¾ªç¯ç¥ç»ç½‘ç»œâ€”â€”å­—ç¬¦é¢„æµ‹\n",
    "## ä½¿ç”¨åµŒå…¥å±‚ä»£æ›¿ç‹¬çƒ­ç¼–ç \n",
    "![dmwb6Q](https://gitee.com/pxqp9W/testmarkdown/raw/master/imgs/2020/07/dmwb6Q.png)\n",
    "![s9VCVx](https://gitee.com/pxqp9W/testmarkdown/raw/master/imgs/2020/07/s9VCVx.png)\n",
    "![MQHFCF](https://gitee.com/pxqp9W/testmarkdown/raw/master/imgs/2020/07/MQHFCF.png)\n",
    "- [ä¸‡ç‰©çš†Embeddingï¼Œä»ç»å…¸çš„word2vecåˆ°æ·±åº¦å­¦ä¹ åŸºæœ¬æ“ä½œitem2vec - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/53194407)\n",
    "- [Embedding çš„ç†è§£ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/46016518)\n",
    "- [æ·±åº¦å­¦ä¹ ä¸­çš„embedding_æ˜Ÿè¾°å¤§æµ·ï¼Œè„šè¸å®åœ°-CSDNåšå®¢_embedding](https://blog.csdn.net/qq_35799003/article/details/84780289)\n",
    "- [æ·±åº¦å­¦ä¹ ä¸­ Embeddingå±‚ä¸¤å¤§ä½œç”¨çš„ä¸ªäººç†è§£_weixin_42078618çš„åšå®¢-CSDNåšå®¢_embeddingå±‚](https://blog.csdn.net/weixin_42078618/article/details/82999906)\n",
    "\n",
    "## åµŒå…¥å±‚çš„ç†è§£\n",
    "- é™ç»´ä½œç”¨ï¼š\n",
    "    - å‡è®¾ï¼šæˆ‘ä»¬æœ‰ä¸€ä¸ª2 x 6çš„çŸ©é˜µï¼Œç„¶åä¹˜ä¸Šä¸€ä¸ª6 x 3çš„çŸ©é˜µåï¼Œå˜æˆäº†ä¸€ä¸ª2 x 3çš„çŸ©é˜µ -> æŠŠä¸€ä¸ª12ä¸ªå…ƒç´ çš„çŸ©é˜µå˜æˆ6ä¸ªå…ƒç´ çš„çŸ©é˜µ\n",
    "    - å‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ª100W X10Wçš„çŸ©é˜µï¼Œç”¨å®ƒä¹˜ä¸Šä¸€ä¸ª10W X 20çš„çŸ©é˜µï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒé™åˆ°100W X 20ï¼Œç¬é—´é‡çº§é™äº†10W/20=5000å€\n",
    "    - è¿™å°±æ˜¯åµŒå…¥å±‚çš„ä¸€ä¸ªä½œç”¨â€”â€”é™ç»´ã€‚ä¸­é—´é‚£ä¸ª 10W X 20çš„çŸ©é˜µï¼Œå¯ä»¥ç†è§£ä¸º**æŸ¥è¯¢è¡¨**ï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸º**æ˜ å°„è¡¨**ï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸º**è¿‡åº¦è¡¨**\n",
    "- æ—¢ç„¶å¯ä»¥é™ç»´ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥å‡ç»´ã€‚\n",
    "    - embeddingçš„åˆä¸€ä¸ªä½œç”¨ä½“ç°äº†ï¼šå¯¹ä½ç»´çš„æ•°æ®è¿›è¡Œå‡ç»´æ—¶ï¼Œå¯èƒ½æŠŠä¸€äº›å…¶ä»–ç‰¹å¾ç»™æ”¾å¤§äº†ï¼Œæˆ–è€…æŠŠç¬¼ç»Ÿçš„ç‰¹å¾ç»™åˆ†å¼€äº†ã€‚\n",
    "    - åŒæ—¶ï¼Œè¿™ä¸ªembeddingæ˜¯ä¸€ç›´åœ¨å­¦ä¹ åœ¨ä¼˜åŒ–çš„ï¼Œå°±ä½¿å¾—æ•´ä¸ªæ‹‰è¿‘æ‹‰è¿œçš„è¿‡ç¨‹æ…¢æ…¢å½¢æˆä¸€ä¸ªè‰¯å¥½çš„è§‚å¯Ÿç‚¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_class = 4 \n",
    "input_size = 4 \n",
    "hidden_size = 8 \n",
    "embedding_size = 10\n",
    "num_layers = 2 \n",
    "batch_size = 1 \n",
    "seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "idx2char = ['e', 'h', 'l', 'o'] # å­—å…¸\n",
    "x_data = [[1, 0, 2, 2, 3]] # hello, æ³¨æ„è¿™é‡Œçš„shape\n",
    "y_data = [3, 1, 2, 3, 2] # ohlol\n",
    "\n",
    "inputs = torch.LongTensor(x_data) \n",
    "labels = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__() \n",
    "        # Lookup matrix of Embedding:ï¼ˆğ’Šğ’ğ’‘ğ’–ğ’•ğ‘ºğ’Šğ’›ğ’†, ğ’†ğ’ğ’ƒğ’†ğ’…ğ’…ğ’Šğ’ğ’ˆğ‘ºğ’Šğ’›ğ’†ï¼‰\n",
    "        self.emb = torch.nn.Embedding(input_size, embedding_size) \n",
    "        # Input of RNN:ï¼ˆğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’†ğ’ğ’ƒğ’†ğ’…ğ’…ğ’Šğ’ğ’ˆğ‘ºğ’Šğ’›ğ’†ï¼‰\n",
    "        # Output of RNN:ï¼ˆğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’‰ğ’Šğ’…ğ’…ğ’†ğ’ğ‘ºğ’Šğ’›ğ’†ï¼‰\n",
    "        self.rnn = torch.nn.RNN(input_size=embedding_size, \n",
    "                                hidden_size=hidden_size, \n",
    "                                num_layers=num_layers, \n",
    "                                batch_first=True)\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(num_layers, x.size( 0), hidden_size) \n",
    "        x = self.emb(x) # (batch, seqLen, embeddingSize) \n",
    "        x, _ = self.rnn(x, hidden) \n",
    "        # Input of FC Layer: ï¼ˆğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’‰ğ’Šğ’…ğ’…ğ’†ğ’ğ‘ºğ’Šğ’›ğ’†ï¼‰\n",
    "        x = self.fc(x) \n",
    "        # Output of FC Layerï¼šï¼ˆğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’ğ’–ğ’ğ‘ªğ’ğ’‚ğ’”ğ’”ï¼‰\n",
    "        return x.view(-1, num_class) # Reshape result to use Cross Entropy\n",
    "\n",
    "net = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  hhhhh, Epoch [1/15] loss = 1.398\n",
      "Predicted:  loolo, Epoch [2/15] loss = 2.079\n",
      "Predicted:  olllh, Epoch [3/15] loss = 1.616\n",
      "Predicted:  ohloo, Epoch [4/15] loss = 0.700\n",
      "Predicted:  ohool, Epoch [5/15] loss = 0.881\n",
      "Predicted:  ohool, Epoch [6/15] loss = 0.586\n",
      "Predicted:  lhlll, Epoch [7/15] loss = 0.583\n",
      "Predicted:  lhlll, Epoch [8/15] loss = 0.557\n",
      "Predicted:  ohlol, Epoch [9/15] loss = 0.176\n",
      "Predicted:  ohlol, Epoch [10/15] loss = 0.037\n",
      "Predicted:  ohlol, Epoch [11/15] loss = 0.021\n",
      "Predicted:  ohlol, Epoch [12/15] loss = 0.018\n",
      "Predicted:  ohlol, Epoch [13/15] loss = 0.015\n",
      "Predicted:  ohlol, Epoch [14/15] loss = 0.012\n",
      "Predicted:  ohlol, Epoch [15/15] loss = 0.013\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    optimizer.zero_grad() \n",
    "    outputs = net(inputs) \n",
    "    loss = criterion(outputs, labels) \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "    _, idx = outputs.max(dim=1) \n",
    "    idx = idx.data.numpy() \n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='') \n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
