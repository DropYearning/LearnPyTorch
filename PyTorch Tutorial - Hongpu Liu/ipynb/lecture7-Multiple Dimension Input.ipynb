{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./dataset/diabetes.csv.gz', delimiter=',', dtype=np.float32) \n",
    "# x_data和y_data都是tensor\n",
    "x_data = torch.from_numpy(xy[:,:-1]) # 最后一列不要\n",
    "y_data = torch.from_numpy(xy[:, [-1]]) # 中括号表示拿出最后一列作为矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__() \n",
    "        self.linear1 = torch.nn.Linear(8, 6) \n",
    "        self.linear2 = torch.nn.Linear(6, 4) \n",
    "        self.linear3 = torch.nn.Linear(4, 1) \n",
    "        self.sigmoid = torch.nn.Sigmoid() # 激活函数也可以选择其他的\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x)) \n",
    "        x = self.sigmoid(self.linear2(x)) \n",
    "        x = self.sigmoid(self.linear3(x)) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct loss and optimizer using PyTorch API\n",
    "criterion = torch.nn.BCELoss(size_average=False) # Logistic Regression使用BCE作为损失函数\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存到list方便作图\n",
    "epoch_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 500.8145751953125\n",
      "1 1921.42236328125\n",
      "2 4793.796875\n",
      "3 4010.550048828125\n",
      "4 619.3806762695312\n",
      "5 3261.974365234375\n",
      "6 26300.0\n",
      "7 26300.0\n",
      "8 26300.0\n",
      "9 26300.0\n",
      "10 26300.0\n",
      "11 26300.0\n",
      "12 26300.0\n",
      "13 26300.0\n",
      "14 26300.0\n",
      "15 26300.0\n",
      "16 26300.0\n",
      "17 26300.0\n",
      "18 26300.0\n",
      "19 26300.0\n",
      "20 26300.0\n",
      "21 26300.0\n",
      "22 26300.0\n",
      "23 26300.0\n",
      "24 26300.0\n",
      "25 26300.0\n",
      "26 26300.0\n",
      "27 26300.0\n",
      "28 26300.0\n",
      "29 26300.0\n",
      "30 26300.0\n",
      "31 26300.0\n",
      "32 26300.0\n",
      "33 26300.0\n",
      "34 26300.0\n",
      "35 26300.0\n",
      "36 26300.0\n",
      "37 26300.0\n",
      "38 26300.0\n",
      "39 26300.0\n",
      "40 26300.0\n",
      "41 26300.0\n",
      "42 26300.0\n",
      "43 26300.0\n",
      "44 26300.0\n",
      "45 26300.0\n",
      "46 26300.0\n",
      "47 26300.0\n",
      "48 26300.0\n",
      "49 26300.0\n",
      "50 26300.0\n",
      "51 26300.0\n",
      "52 26300.0\n",
      "53 26300.0\n",
      "54 26300.0\n",
      "55 26300.0\n",
      "56 26300.0\n",
      "57 26300.0\n",
      "58 26300.0\n",
      "59 26300.0\n",
      "60 26300.0\n",
      "61 26300.0\n",
      "62 26300.0\n",
      "63 26300.0\n",
      "64 26300.0\n",
      "65 26300.0\n",
      "66 26300.0\n",
      "67 26300.0\n",
      "68 26300.0\n",
      "69 26300.0\n",
      "70 26300.0\n",
      "71 26300.0\n",
      "72 26300.0\n",
      "73 26300.0\n",
      "74 26300.0\n",
      "75 26300.0\n",
      "76 26300.0\n",
      "77 26300.0\n",
      "78 26300.0\n",
      "79 26300.0\n",
      "80 26300.0\n",
      "81 26300.0\n",
      "82 26300.0\n",
      "83 26300.0\n",
      "84 26300.0\n",
      "85 26300.0\n",
      "86 26300.0\n",
      "87 26300.0\n",
      "88 26300.0\n",
      "89 26300.0\n",
      "90 26300.0\n",
      "91 26300.0\n",
      "92 26300.0\n",
      "93 26300.0\n",
      "94 26300.0\n",
      "95 26300.0\n",
      "96 26300.0\n",
      "97 26300.0\n",
      "98 26300.0\n",
      "99 26300.0\n"
     ]
    }
   ],
   "source": [
    "# Training cycle\n",
    "for epoch in range(100):\n",
    "    epoch_list.append(epoch)\n",
    "    # forward\n",
    "    y_pred = model(x_data) # 实际上调用的是LinearModel.forward()函数\n",
    "    loss = criterion(y_pred, y_data) \n",
    "    loss_list.append(loss.item())\n",
    "    print(epoch, loss.item())\n",
    "    # 在backward前将权重清零\n",
    "    optimizer.zero_grad() \n",
    "    # backward\n",
    "    loss.backward() \n",
    "    # update\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
