{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0] \n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "w1 = torch.Tensor([1.0])  # 权重初始值\n",
    "w2 = torch.Tensor([1.0])  # 权重初始值\n",
    "b = torch.Tensor([1.0]) \n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w1 * x ** 2 + w2 * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x, y):\n",
    "    y_pred = forward(x) \n",
    "    return (y_pred - y) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 21.0\n",
      "\t grad: 1.0 2.0 2.0 2.0 2.0\n",
      "\t grad: 2.0 4.0 22.880001068115234 11.440000534057617 5.720000267028809\n",
      "\t grad: 3.0 6.0 77.04720306396484 25.682401657104492 8.560800552368164\n",
      "progress: 0 18.321826934814453\n",
      "\t grad: 1.0 2.0 -1.1466078758239746 -1.1466078758239746 -1.1466078758239746\n",
      "\t grad: 2.0 4.0 -15.536651611328125 -7.7683258056640625 -3.8841629028320312\n",
      "\t grad: 3.0 6.0 -30.432214736938477 -10.144071578979492 -3.381357192993164\n",
      "progress: 1 2.858394145965576\n",
      "\t grad: 1.0 2.0 0.3451242446899414 0.3451242446899414 0.3451242446899414\n",
      "\t grad: 2.0 4.0 2.4273414611816406 1.2136707305908203 0.6068353652954102\n",
      "\t grad: 3.0 6.0 19.449920654296875 6.483306884765625 2.161102294921875\n",
      "progress: 2 1.1675907373428345\n",
      "\t grad: 1.0 2.0 -0.32242679595947266 -0.32242679595947266 -0.32242679595947266\n",
      "\t grad: 2.0 4.0 -5.845773696899414 -2.922886848449707 -1.4614434242248535\n",
      "\t grad: 3.0 6.0 -3.8828859329223633 -1.294295310974121 -0.43143177032470703\n",
      "progress: 3 0.04653334245085716\n",
      "\t grad: 1.0 2.0 0.01369333267211914 0.01369333267211914 0.01369333267211914\n",
      "\t grad: 2.0 4.0 -1.9140911102294922 -0.9570455551147461 -0.47852277755737305\n",
      "\t grad: 3.0 6.0 6.855700492858887 2.285233497619629 0.761744499206543\n",
      "progress: 4 0.14506366848945618\n",
      "\t grad: 1.0 2.0 -0.11818885803222656 -0.11818885803222656 -0.11818885803222656\n",
      "\t grad: 2.0 4.0 -3.664388656616211 -1.8321943283081055 -0.9160971641540527\n",
      "\t grad: 3.0 6.0 1.7454700469970703 0.5818233489990234 0.1939411163330078\n",
      "progress: 5 0.009403289295732975\n",
      "\t grad: 1.0 2.0 -0.03326845169067383 -0.03326845169067383 -0.03326845169067383\n",
      "\t grad: 2.0 4.0 -2.7738723754882812 -1.3869361877441406 -0.6934680938720703\n",
      "\t grad: 3.0 6.0 4.014009475708008 1.338003158569336 0.4460010528564453\n",
      "progress: 6 0.04972923547029495\n",
      "\t grad: 1.0 2.0 -0.050147056579589844 -0.050147056579589844 -0.050147056579589844\n",
      "\t grad: 2.0 4.0 -3.1150074005126953 -1.5575037002563477 -0.7787518501281738\n",
      "\t grad: 3.0 6.0 2.8533897399902344 0.9511299133300781 0.3170433044433594\n",
      "progress: 7 0.025129113346338272\n",
      "\t grad: 1.0 2.0 -0.020544052124023438 -0.020544052124023438 -0.020544052124023438\n",
      "\t grad: 2.0 4.0 -2.8858280181884766 -1.4429140090942383 -0.7214570045471191\n",
      "\t grad: 3.0 6.0 3.292379379272461 1.0974597930908203 0.36581993103027344\n",
      "progress: 8 0.03345605731010437\n",
      "\t grad: 1.0 2.0 -0.013420581817626953 -0.013420581817626953 -0.013420581817626953\n",
      "\t grad: 2.0 4.0 -2.9246826171875 -1.46234130859375 -0.731170654296875\n",
      "\t grad: 3.0 6.0 2.990907669067383 0.9969692230224609 0.3323230743408203\n",
      "progress: 9 0.027609655633568764\n",
      "\t grad: 1.0 2.0 0.0033445358276367188 0.0033445358276367188 0.0033445358276367188\n",
      "\t grad: 2.0 4.0 -2.841381072998047 -1.4206905364990234 -0.7103452682495117\n",
      "\t grad: 3.0 6.0 3.0377025604248047 1.0125675201416016 0.3375225067138672\n",
      "progress: 10 0.02848036028444767\n",
      "\t grad: 1.0 2.0 0.014836311340332031 0.014836311340332031 0.014836311340332031\n",
      "\t grad: 2.0 4.0 -2.8173885345458984 -1.4086942672729492 -0.7043471336364746\n",
      "\t grad: 3.0 6.0 2.9260196685791016 0.9753398895263672 0.32511329650878906\n",
      "progress: 11 0.02642466314136982\n",
      "\t grad: 1.0 2.0 0.028025150299072266 0.028025150299072266 0.028025150299072266\n",
      "\t grad: 2.0 4.0 -2.768169403076172 -1.384084701538086 -0.692042350769043\n",
      "\t grad: 3.0 6.0 2.891498565673828 0.9638328552246094 0.3212776184082031\n",
      "progress: 12 0.025804826989769936\n",
      "\t grad: 1.0 2.0 0.03969764709472656 0.03969764709472656 0.03969764709472656\n",
      "\t grad: 2.0 4.0 -2.732961654663086 -1.366480827331543 -0.6832404136657715\n",
      "\t grad: 3.0 6.0 2.8243446350097656 0.9414482116699219 0.3138160705566406\n",
      "progress: 13 0.02462013065814972\n",
      "\t grad: 1.0 2.0 0.051377296447753906 0.051377296447753906 0.051377296447753906\n",
      "\t grad: 2.0 4.0 -2.6934165954589844 -1.3467082977294922 -0.6733541488647461\n",
      "\t grad: 3.0 6.0 2.7755842208862305 0.9251947402954102 0.3083982467651367\n",
      "progress: 14 0.023777369409799576\n",
      "\t grad: 1.0 2.0 0.062380313873291016 0.062380313873291016 0.062380313873291016\n",
      "\t grad: 2.0 4.0 -2.6580047607421875 -1.3290023803710938 -0.6645011901855469\n",
      "\t grad: 3.0 6.0 2.7212963104248047 0.9070987701416016 0.3023662567138672\n",
      "progress: 15 0.0228563379496336\n",
      "\t grad: 1.0 2.0 0.07305240631103516 0.07305240631103516 0.07305240631103516\n",
      "\t grad: 2.0 4.0 -2.622692108154297 -1.3113460540771484 -0.6556730270385742\n",
      "\t grad: 3.0 6.0 2.672501564025879 0.890833854675293 0.29694461822509766\n",
      "progress: 16 0.022044027224183083\n",
      "\t grad: 1.0 2.0 0.08325767517089844 0.08325767517089844 0.08325767517089844\n",
      "\t grad: 2.0 4.0 -2.589275360107422 -1.294637680053711 -0.6473188400268555\n",
      "\t grad: 3.0 6.0 2.6239728927612305 0.8746576309204102 0.2915525436401367\n",
      "progress: 17 0.02125072106719017\n",
      "\t grad: 1.0 2.0 0.09308338165283203 0.09308338165283203 0.09308338165283203\n",
      "\t grad: 2.0 4.0 -2.5568485260009766 -1.2784242630004883 -0.6392121315002441\n",
      "\t grad: 3.0 6.0 2.578036308288574 0.8593454360961914 0.28644847869873047\n",
      "progress: 18 0.020513182505965233\n",
      "\t grad: 1.0 2.0 0.10251188278198242 0.10251188278198242 0.10251188278198242\n",
      "\t grad: 2.0 4.0 -2.5257606506347656 -1.2628803253173828 -0.6314401626586914\n",
      "\t grad: 3.0 6.0 2.5334815979003906 0.8444938659667969 0.2814979553222656\n",
      "progress: 19 0.019810274243354797\n",
      "\t grad: 1.0 2.0 0.1115732192993164 0.1115732192993164 0.1115732192993164\n",
      "\t grad: 2.0 4.0 -2.4957752227783203 -1.2478876113891602 -0.6239438056945801\n",
      "\t grad: 3.0 6.0 2.490780830383301 0.8302602767944336 0.27675342559814453\n",
      "progress: 20 0.019148115068674088\n",
      "\t grad: 1.0 2.0 0.12027454376220703 0.12027454376220703 0.12027454376220703\n",
      "\t grad: 2.0 4.0 -2.4669342041015625 -1.2334671020507812 -0.6167335510253906\n",
      "\t grad: 3.0 6.0 2.4496335983276367 0.8165445327758789 0.27218151092529297\n",
      "progress: 21 0.018520694226026535\n",
      "\t grad: 1.0 2.0 0.12863397598266602 0.12863397598266602 0.12863397598266602\n",
      "\t grad: 2.0 4.0 -2.4391613006591797 -1.2195806503295898 -0.6097903251647949\n",
      "\t grad: 3.0 6.0 2.4100828170776367 0.8033609390258789 0.26778697967529297\n",
      "progress: 22 0.017927465960383415\n",
      "\t grad: 1.0 2.0 0.13666200637817383 0.13666200637817383 0.13666200637817383\n",
      "\t grad: 2.0 4.0 -2.4124298095703125 -1.2062149047851562 -0.6031074523925781\n",
      "\t grad: 3.0 6.0 2.3719911575317383 0.7906637191772461 0.26355457305908203\n",
      "progress: 23 0.01736525259912014\n",
      "\t grad: 1.0 2.0 0.14437294006347656 0.14437294006347656 0.14437294006347656\n",
      "\t grad: 2.0 4.0 -2.386688232421875 -1.1933441162109375 -0.5966720581054688\n",
      "\t grad: 3.0 6.0 2.335367202758789 0.7784557342529297 0.25948524475097656\n",
      "progress: 24 0.016833148896694183\n",
      "\t grad: 1.0 2.0 0.1517786979675293 0.1517786979675293 0.1517786979675293\n",
      "\t grad: 2.0 4.0 -2.3619022369384766 -1.1809511184692383 -0.5904755592346191\n",
      "\t grad: 3.0 6.0 2.30013370513916 0.7667112350463867 0.2555704116821289\n",
      "progress: 25 0.01632905937731266\n",
      "\t grad: 1.0 2.0 0.1588902473449707 0.1588902473449707 0.1588902473449707\n",
      "\t grad: 2.0 4.0 -2.338043212890625 -1.1690216064453125 -0.5845108032226562\n",
      "\t grad: 3.0 6.0 2.2661962509155273 0.7553987503051758 0.2517995834350586\n",
      "progress: 26 0.01585075818002224\n",
      "\t grad: 1.0 2.0 0.16572046279907227 0.16572046279907227 0.16572046279907227\n",
      "\t grad: 2.0 4.0 -2.3150596618652344 -1.1575298309326172 -0.5787649154663086\n",
      "\t grad: 3.0 6.0 2.233572006225586 0.7445240020751953 0.24817466735839844\n",
      "progress: 27 0.015397666022181511\n",
      "\t grad: 1.0 2.0 0.17227888107299805 0.17227888107299805 0.17227888107299805\n",
      "\t grad: 2.0 4.0 -2.2929306030273438 -1.1464653015136719 -0.5732326507568359\n",
      "\t grad: 3.0 6.0 2.202157974243164 0.7340526580810547 0.24468421936035156\n",
      "progress: 28 0.014967591501772404\n",
      "\t grad: 1.0 2.0 0.17857694625854492 0.17857694625854492 0.17857694625854492\n",
      "\t grad: 2.0 4.0 -2.271617889404297 -1.1358089447021484 -0.5679044723510742\n",
      "\t grad: 3.0 6.0 2.171945571899414 0.7239818572998047 0.24132728576660156\n",
      "progress: 29 0.014559715054929256\n",
      "\t grad: 1.0 2.0 0.18462371826171875 0.18462371826171875 0.18462371826171875\n",
      "\t grad: 2.0 4.0 -2.2510948181152344 -1.1255474090576172 -0.5627737045288086\n",
      "\t grad: 3.0 6.0 2.142857551574707 0.7142858505249023 0.23809528350830078\n",
      "progress: 30 0.014172340743243694\n",
      "\t grad: 1.0 2.0 0.1904296875 0.1904296875 0.1904296875\n",
      "\t grad: 2.0 4.0 -2.231321334838867 -1.1156606674194336 -0.5578303337097168\n",
      "\t grad: 3.0 6.0 2.1148509979248047 0.7049503326416016 0.2349834442138672\n",
      "progress: 31 0.013804304413497448\n",
      "\t grad: 1.0 2.0 0.19600486755371094 0.19600486755371094 0.19600486755371094\n",
      "\t grad: 2.0 4.0 -2.2122726440429688 -1.1061363220214844 -0.5530681610107422\n",
      "\t grad: 3.0 6.0 2.087925910949707 0.6959753036499023 0.23199176788330078\n",
      "progress: 32 0.013455045409500599\n",
      "\t grad: 1.0 2.0 0.2013559341430664 0.2013559341430664 0.2013559341430664\n",
      "\t grad: 2.0 4.0 -2.193929672241211 -1.0969648361206055 -0.5484824180603027\n",
      "\t grad: 3.0 6.0 2.061979293823242 0.6873264312744141 0.2291088104248047\n",
      "progress: 33 0.013122711330652237\n",
      "\t grad: 1.0 2.0 0.20649433135986328 0.20649433135986328 0.20649433135986328\n",
      "\t grad: 2.0 4.0 -2.176250457763672 -1.088125228881836 -0.544062614440918\n",
      "\t grad: 3.0 6.0 2.037019729614258 0.6790065765380859 0.2263355255126953\n",
      "progress: 34 0.01280694268643856\n",
      "\t grad: 1.0 2.0 0.21142578125 0.21142578125 0.21142578125\n",
      "\t grad: 2.0 4.0 -2.1592159271240234 -1.0796079635620117 -0.5398039817810059\n",
      "\t grad: 3.0 6.0 2.0130043029785156 0.6710014343261719 0.22366714477539062\n",
      "progress: 35 0.012506747618317604\n",
      "\t grad: 1.0 2.0 0.21615982055664062 0.21615982055664062 0.21615982055664062\n",
      "\t grad: 2.0 4.0 -2.142810821533203 -1.0714054107666016 -0.5357027053833008\n",
      "\t grad: 3.0 6.0 1.9898557662963867 0.6632852554321289 0.22109508514404297\n",
      "progress: 36 0.012220758944749832\n",
      "\t grad: 1.0 2.0 0.2207036018371582 0.2207036018371582 0.2207036018371582\n",
      "\t grad: 2.0 4.0 -2.1269912719726562 -1.0634956359863281 -0.5317478179931641\n",
      "\t grad: 3.0 6.0 1.967599868774414 0.6558666229248047 0.21862220764160156\n",
      "progress: 37 0.01194891706109047\n",
      "\t grad: 1.0 2.0 0.22506427764892578 0.22506427764892578 0.22506427764892578\n",
      "\t grad: 2.0 4.0 -2.1117515563964844 -1.0558757781982422 -0.5279378890991211\n",
      "\t grad: 3.0 6.0 1.9461593627929688 0.6487197875976562 0.21623992919921875\n",
      "progress: 38 0.011689926497638226\n",
      "\t grad: 1.0 2.0 0.2292490005493164 0.2292490005493164 0.2292490005493164\n",
      "\t grad: 2.0 4.0 -2.0970611572265625 -1.0485305786132812 -0.5242652893066406\n",
      "\t grad: 3.0 6.0 1.9255084991455078 0.6418361663818359 0.2139453887939453\n",
      "progress: 39 0.01144315768033266\n",
      "\t grad: 1.0 2.0 0.23326539993286133 0.23326539993286133 0.23326539993286133\n",
      "\t grad: 2.0 4.0 -2.082897186279297 -1.0414485931396484 -0.5207242965698242\n",
      "\t grad: 3.0 6.0 1.9056644439697266 0.6352214813232422 0.21174049377441406\n",
      "progress: 40 0.011208509095013142\n",
      "\t grad: 1.0 2.0 0.23711872100830078 0.23711872100830078 0.23711872100830078\n",
      "\t grad: 2.0 4.0 -2.0692520141601562 -1.0346260070800781 -0.5173130035400391\n",
      "\t grad: 3.0 6.0 1.8864898681640625 0.6288299560546875 0.2096099853515625\n",
      "progress: 41 0.0109840864315629\n",
      "\t grad: 1.0 2.0 0.24081659317016602 0.24081659317016602 0.24081659317016602\n",
      "\t grad: 2.0 4.0 -2.0560836791992188 -1.0280418395996094 -0.5140209197998047\n",
      "\t grad: 3.0 6.0 1.8680963516235352 0.6226987838745117 0.2075662612915039\n",
      "progress: 42 0.010770938359200954\n",
      "\t grad: 1.0 2.0 0.24436283111572266 0.24436283111572266 0.24436283111572266\n",
      "\t grad: 2.0 4.0 -2.0433998107910156 -1.0216999053955078 -0.5108499526977539\n",
      "\t grad: 3.0 6.0 1.850320816040039 0.6167736053466797 0.20559120178222656\n",
      "progress: 43 0.010566935874521732\n",
      "\t grad: 1.0 2.0 0.24776697158813477 0.24776697158813477 0.24776697158813477\n",
      "\t grad: 2.0 4.0 -2.0311546325683594 -1.0155773162841797 -0.5077886581420898\n",
      "\t grad: 3.0 6.0 1.8332405090332031 0.6110801696777344 0.20369338989257812\n",
      "progress: 44 0.010372749529778957\n",
      "\t grad: 1.0 2.0 0.25103092193603516 0.25103092193603516 0.25103092193603516\n",
      "\t grad: 2.0 4.0 -2.0193519592285156 -1.0096759796142578 -0.5048379898071289\n",
      "\t grad: 3.0 6.0 1.816786766052246 0.605595588684082 0.20186519622802734\n",
      "progress: 45 0.010187389329075813\n",
      "\t grad: 1.0 2.0 0.2541618347167969 0.2541618347167969 0.2541618347167969\n",
      "\t grad: 2.0 4.0 -2.0079689025878906 -1.0039844512939453 -0.5019922256469727\n",
      "\t grad: 3.0 6.0 1.8009252548217773 0.6003084182739258 0.2001028060913086\n",
      "progress: 46 0.010010283440351486\n",
      "\t grad: 1.0 2.0 0.25716400146484375 0.25716400146484375 0.25716400146484375\n",
      "\t grad: 2.0 4.0 -1.9969863891601562 -0.9984931945800781 -0.49924659729003906\n",
      "\t grad: 3.0 6.0 1.785630226135254 0.595210075378418 0.19840335845947266\n",
      "progress: 47 0.00984097272157669\n",
      "\t grad: 1.0 2.0 0.2600440979003906 0.2600440979003906 0.2600440979003906\n",
      "\t grad: 2.0 4.0 -1.9863853454589844 -0.9931926727294922 -0.4965963363647461\n",
      "\t grad: 3.0 6.0 1.7709360122680664 0.5903120040893555 0.19677066802978516\n",
      "progress: 48 0.009679674170911312\n",
      "\t grad: 1.0 2.0 0.2628040313720703 0.2628040313720703 0.2628040313720703\n",
      "\t grad: 2.0 4.0 -1.976165771484375 -0.9880828857421875 -0.49404144287109375\n",
      "\t grad: 3.0 6.0 1.7567567825317383 0.5855855941772461 0.19519519805908203\n",
      "progress: 49 0.009525291621685028\n",
      "\t grad: 1.0 2.0 0.26545143127441406 0.26545143127441406 0.26545143127441406\n",
      "\t grad: 2.0 4.0 -1.9663009643554688 -0.9831504821777344 -0.4915752410888672\n",
      "\t grad: 3.0 6.0 1.7430925369262695 0.5810308456420898 0.19367694854736328\n",
      "progress: 50 0.00937769003212452\n",
      "\t grad: 1.0 2.0 0.2679886817932129 0.2679886817932129 0.2679886817932129\n",
      "\t grad: 2.0 4.0 -1.9567756652832031 -0.9783878326416016 -0.4891939163208008\n",
      "\t grad: 3.0 6.0 1.7299346923828125 0.5766448974609375 0.1922149658203125\n",
      "progress: 51 0.009236648678779602\n",
      "\t grad: 1.0 2.0 0.27042055130004883 0.27042055130004883 0.27042055130004883\n",
      "\t grad: 2.0 4.0 -1.9475860595703125 -0.9737930297851562 -0.4868965148925781\n",
      "\t grad: 3.0 6.0 1.717240333557129 0.572413444519043 0.19080448150634766\n",
      "progress: 52 0.00910158734768629\n",
      "\t grad: 1.0 2.0 0.2727518081665039 0.2727518081665039 0.2727518081665039\n",
      "\t grad: 2.0 4.0 -1.9387092590332031 -0.9693546295166016 -0.4846773147583008\n",
      "\t grad: 3.0 6.0 1.705026626586914 0.5683422088623047 0.18944740295410156\n",
      "progress: 53 0.00897257961332798\n",
      "\t grad: 1.0 2.0 0.27498531341552734 0.27498531341552734 0.27498531341552734\n",
      "\t grad: 2.0 4.0 -1.9301414489746094 -0.9650707244873047 -0.48253536224365234\n",
      "\t grad: 3.0 6.0 1.6932334899902344 0.5644111633300781 0.18813705444335938\n",
      "progress: 54 0.008848887868225574\n",
      "\t grad: 1.0 2.0 0.27712535858154297 0.27712535858154297 0.27712535858154297\n",
      "\t grad: 2.0 4.0 -1.9218635559082031 -0.9609317779541016 -0.4804658889770508\n",
      "\t grad: 3.0 6.0 1.6818780899047852 0.5606260299682617 0.1868753433227539\n",
      "progress: 55 0.008730598725378513\n",
      "\t grad: 1.0 2.0 0.2791757583618164 0.2791757583618164 0.2791757583618164\n",
      "\t grad: 2.0 4.0 -1.9138717651367188 -0.9569358825683594 -0.4784679412841797\n",
      "\t grad: 3.0 6.0 1.6709346771240234 0.5569782257080078 0.18565940856933594\n",
      "progress: 56 0.00861735362559557\n",
      "\t grad: 1.0 2.0 0.2811393737792969 0.2811393737792969 0.2811393737792969\n",
      "\t grad: 2.0 4.0 -1.9061508178710938 -0.9530754089355469 -0.47653770446777344\n",
      "\t grad: 3.0 6.0 1.6603689193725586 0.5534563064575195 0.18448543548583984\n",
      "progress: 57 0.008508718572556973\n",
      "\t grad: 1.0 2.0 0.28302001953125 0.28302001953125 0.28302001953125\n",
      "\t grad: 2.0 4.0 -1.8986892700195312 -0.9493446350097656 -0.4746723175048828\n",
      "\t grad: 3.0 6.0 1.6501893997192383 0.5500631332397461 0.18335437774658203\n",
      "progress: 58 0.008404706604778767\n",
      "\t grad: 1.0 2.0 0.284820556640625 0.284820556640625 0.284820556640625\n",
      "\t grad: 2.0 4.0 -1.8914775848388672 -0.9457387924194336 -0.4728693962097168\n",
      "\t grad: 3.0 6.0 1.6403875350952148 0.5467958450317383 0.1822652816772461\n",
      "progress: 59 0.008305158466100693\n",
      "\t grad: 1.0 2.0 0.2865438461303711 0.2865438461303711 0.2865438461303711\n",
      "\t grad: 2.0 4.0 -1.8845138549804688 -0.9422569274902344 -0.4711284637451172\n",
      "\t grad: 3.0 6.0 1.630894660949707 0.5436315536499023 0.18121051788330078\n",
      "progress: 60 0.00820931326597929\n",
      "\t grad: 1.0 2.0 0.2881946563720703 0.2881946563720703 0.2881946563720703\n",
      "\t grad: 2.0 4.0 -1.8777713775634766 -0.9388856887817383 -0.46944284439086914\n",
      "\t grad: 3.0 6.0 1.621779441833496 0.540593147277832 0.18019771575927734\n",
      "progress: 61 0.008117804303765297\n",
      "\t grad: 1.0 2.0 0.28977346420288086 0.28977346420288086 0.28977346420288086\n",
      "\t grad: 2.0 4.0 -1.8712615966796875 -0.9356307983398438 -0.4678153991699219\n",
      "\t grad: 3.0 6.0 1.6129646301269531 0.5376548767089844 0.17921829223632812\n",
      "progress: 62 0.008029798977077007\n",
      "\t grad: 1.0 2.0 0.29128456115722656 0.29128456115722656 0.29128456115722656\n",
      "\t grad: 2.0 4.0 -1.8649616241455078 -0.9324808120727539 -0.46624040603637695\n",
      "\t grad: 3.0 6.0 1.6044673919677734 0.5348224639892578 0.17827415466308594\n",
      "progress: 63 0.007945418357849121\n",
      "\t grad: 1.0 2.0 0.29272985458374023 0.29272985458374023 0.29272985458374023\n",
      "\t grad: 2.0 4.0 -1.8588676452636719 -0.9294338226318359 -0.46471691131591797\n",
      "\t grad: 3.0 6.0 1.5962448120117188 0.5320816040039062 0.17736053466796875\n",
      "progress: 64 0.007864190265536308\n",
      "\t grad: 1.0 2.0 0.2941126823425293 0.2941126823425293 0.2941126823425293\n",
      "\t grad: 2.0 4.0 -1.8529701232910156 -0.9264850616455078 -0.4632425308227539\n",
      "\t grad: 3.0 6.0 1.5883655548095703 0.5294551849365234 0.1764850616455078\n",
      "progress: 65 0.007786744274199009\n",
      "\t grad: 1.0 2.0 0.29543399810791016 0.29543399810791016 0.29543399810791016\n",
      "\t grad: 2.0 4.0 -1.8472747802734375 -0.9236373901367188 -0.4618186950683594\n",
      "\t grad: 3.0 6.0 1.5806922912597656 0.5268974304199219 0.17563247680664062\n",
      "progress: 66 0.007711691781878471\n",
      "\t grad: 1.0 2.0 0.29669761657714844 0.29669761657714844 0.29669761657714844\n",
      "\t grad: 2.0 4.0 -1.841745376586914 -0.920872688293457 -0.4604363441467285\n",
      "\t grad: 3.0 6.0 1.5733451843261719 0.5244483947753906 0.17481613159179688\n",
      "progress: 67 0.007640169933438301\n",
      "\t grad: 1.0 2.0 0.29790449142456055 0.29790449142456055 0.29790449142456055\n",
      "\t grad: 2.0 4.0 -1.8364067077636719 -0.9182033538818359 -0.45910167694091797\n",
      "\t grad: 3.0 6.0 1.5662040710449219 0.5220680236816406 0.17402267456054688\n",
      "progress: 68 0.007570972666144371\n",
      "\t grad: 1.0 2.0 0.2990589141845703 0.2990589141845703 0.2990589141845703\n",
      "\t grad: 2.0 4.0 -1.8312263488769531 -0.9156131744384766 -0.4578065872192383\n",
      "\t grad: 3.0 6.0 1.5593376159667969 0.5197792053222656 0.17325973510742188\n",
      "progress: 69 0.007504733745008707\n",
      "\t grad: 1.0 2.0 0.30016040802001953 0.30016040802001953 0.30016040802001953\n",
      "\t grad: 2.0 4.0 -1.8262138366699219 -0.9131069183349609 -0.45655345916748047\n",
      "\t grad: 3.0 6.0 1.552694320678711 0.5175647735595703 0.17252159118652344\n",
      "progress: 70 0.007440924644470215\n",
      "\t grad: 1.0 2.0 0.30121278762817383 0.30121278762817383 0.30121278762817383\n",
      "\t grad: 2.0 4.0 -1.8213577270507812 -0.9106788635253906 -0.4553394317626953\n",
      "\t grad: 3.0 6.0 1.5462827682495117 0.5154275894165039 0.17180919647216797\n",
      "progress: 71 0.007379599846899509\n",
      "\t grad: 1.0 2.0 0.3022174835205078 0.3022174835205078 0.3022174835205078\n",
      "\t grad: 2.0 4.0 -1.8166522979736328 -0.9083261489868164 -0.4541630744934082\n",
      "\t grad: 3.0 6.0 1.5400772094726562 0.5133590698242188 0.17111968994140625\n",
      "progress: 72 0.007320486940443516\n",
      "\t grad: 1.0 2.0 0.3031759262084961 0.3031759262084961 0.3031759262084961\n",
      "\t grad: 2.0 4.0 -1.8120880126953125 -0.9060440063476562 -0.4530220031738281\n",
      "\t grad: 3.0 6.0 1.5340948104858398 0.5113649368286133 0.1704549789428711\n",
      "progress: 73 0.007263725157827139\n",
      "\t grad: 1.0 2.0 0.3040900230407715 0.3040900230407715 0.3040900230407715\n",
      "\t grad: 2.0 4.0 -1.8076667785644531 -0.9038333892822266 -0.4519166946411133\n",
      "\t grad: 3.0 6.0 1.5283098220825195 0.5094366073608398 0.16981220245361328\n",
      "progress: 74 0.007209045812487602\n",
      "\t grad: 1.0 2.0 0.304962158203125 0.304962158203125 0.304962158203125\n",
      "\t grad: 2.0 4.0 -1.8033790588378906 -0.9016895294189453 -0.45084476470947266\n",
      "\t grad: 3.0 6.0 1.5227222442626953 0.5075740814208984 0.1691913604736328\n",
      "progress: 75 0.007156429346650839\n",
      "\t grad: 1.0 2.0 0.30579280853271484 0.30579280853271484 0.30579280853271484\n",
      "\t grad: 2.0 4.0 -1.7992210388183594 -0.8996105194091797 -0.44980525970458984\n",
      "\t grad: 3.0 6.0 1.5172977447509766 0.5057659149169922 0.16858863830566406\n",
      "progress: 76 0.007105532102286816\n",
      "\t grad: 1.0 2.0 0.30658483505249023 0.30658483505249023 0.30658483505249023\n",
      "\t grad: 2.0 4.0 -1.7951812744140625 -0.8975906372070312 -0.4487953186035156\n",
      "\t grad: 3.0 6.0 1.5120878219604492 0.5040292739868164 0.16800975799560547\n",
      "progress: 77 0.00705681974068284\n",
      "\t grad: 1.0 2.0 0.3073387145996094 0.3073387145996094 0.3073387145996094\n",
      "\t grad: 2.0 4.0 -1.791269302368164 -0.895634651184082 -0.447817325592041\n",
      "\t grad: 3.0 6.0 1.5070152282714844 0.5023384094238281 0.16744613647460938\n",
      "progress: 78 0.007009552326053381\n",
      "\t grad: 1.0 2.0 0.3080568313598633 0.3080568313598633 0.3080568313598633\n",
      "\t grad: 2.0 4.0 -1.7874603271484375 -0.8937301635742188 -0.4468650817871094\n",
      "\t grad: 3.0 6.0 1.502131462097168 0.5007104873657227 0.16690349578857422\n",
      "progress: 79 0.006964194122701883\n",
      "\t grad: 1.0 2.0 0.30873966217041016 0.30873966217041016 0.30873966217041016\n",
      "\t grad: 2.0 4.0 -1.7837696075439453 -0.8918848037719727 -0.44594240188598633\n",
      "\t grad: 3.0 6.0 1.4973936080932617 0.4991312026977539 0.16637706756591797\n",
      "progress: 80 0.006920332089066505\n",
      "\t grad: 1.0 2.0 0.309389591217041 0.309389591217041 0.309389591217041\n",
      "\t grad: 2.0 4.0 -1.780181884765625 -0.8900909423828125 -0.44504547119140625\n",
      "\t grad: 3.0 6.0 1.492818832397461 0.4976062774658203 0.16586875915527344\n",
      "progress: 81 0.006878111511468887\n",
      "\t grad: 1.0 2.0 0.31000614166259766 0.31000614166259766 0.31000614166259766\n",
      "\t grad: 2.0 4.0 -1.7766971588134766 -0.8883485794067383 -0.44417428970336914\n",
      "\t grad: 3.0 6.0 1.4883899688720703 0.49612998962402344 0.1653766632080078\n",
      "progress: 82 0.006837360095232725\n",
      "\t grad: 1.0 2.0 0.3105926513671875 0.3105926513671875 0.3105926513671875\n",
      "\t grad: 2.0 4.0 -1.7733135223388672 -0.8866567611694336 -0.4433283805847168\n",
      "\t grad: 3.0 6.0 1.4840812683105469 0.4946937561035156 0.16489791870117188\n",
      "progress: 83 0.006797831039875746\n",
      "\t grad: 1.0 2.0 0.31114959716796875 0.31114959716796875 0.31114959716796875\n",
      "\t grad: 2.0 4.0 -1.7700138092041016 -0.8850069046020508 -0.4425034523010254\n",
      "\t grad: 3.0 6.0 1.4799528121948242 0.4933176040649414 0.16443920135498047\n",
      "progress: 84 0.006760062649846077\n",
      "\t grad: 1.0 2.0 0.3116769790649414 0.3116769790649414 0.3116769790649414\n",
      "\t grad: 2.0 4.0 -1.7668170928955078 -0.8834085464477539 -0.44170427322387695\n",
      "\t grad: 3.0 6.0 1.4759016036987305 0.49196720123291016 0.16398906707763672\n",
      "progress: 85 0.006723103579133749\n",
      "\t grad: 1.0 2.0 0.3121776580810547 0.3121776580810547 0.3121776580810547\n",
      "\t grad: 2.0 4.0 -1.7636966705322266 -0.8818483352661133 -0.44092416763305664\n",
      "\t grad: 3.0 6.0 1.4720134735107422 0.49067115783691406 0.1635570526123047\n",
      "progress: 86 0.00668772729113698\n",
      "\t grad: 1.0 2.0 0.3126516342163086 0.3126516342163086 0.3126516342163086\n",
      "\t grad: 2.0 4.0 -1.7606639862060547 -0.8803319931030273 -0.44016599655151367\n",
      "\t grad: 3.0 6.0 1.4682197570800781 0.4894065856933594 0.16313552856445312\n",
      "progress: 87 0.006653300020843744\n",
      "\t grad: 1.0 2.0 0.31310081481933594 0.31310081481933594 0.31310081481933594\n",
      "\t grad: 2.0 4.0 -1.7577095031738281 -0.8788547515869141 -0.43942737579345703\n",
      "\t grad: 3.0 6.0 1.4645805358886719 0.4881935119628906 0.16273117065429688\n",
      "progress: 88 0.0066203586757183075\n",
      "\t grad: 1.0 2.0 0.3135242462158203 0.3135242462158203 0.3135242462158203\n",
      "\t grad: 2.0 4.0 -1.754842758178711 -0.8774213790893555 -0.43871068954467773\n",
      "\t grad: 3.0 6.0 1.4610099792480469 0.4870033264160156 0.16233444213867188\n",
      "progress: 89 0.0065881176851689816\n",
      "\t grad: 1.0 2.0 0.31392478942871094 0.31392478942871094 0.31392478942871094\n",
      "\t grad: 2.0 4.0 -1.7520370483398438 -0.8760185241699219 -0.43800926208496094\n",
      "\t grad: 3.0 6.0 1.457585334777832 0.48586177825927734 0.16195392608642578\n",
      "progress: 90 0.0065572685562074184\n",
      "\t grad: 1.0 2.0 0.314302921295166 0.314302921295166 0.314302921295166\n",
      "\t grad: 2.0 4.0 -1.7493114471435547 -0.8746557235717773 -0.43732786178588867\n",
      "\t grad: 3.0 6.0 1.4542293548583984 0.4847431182861328 0.16158103942871094\n",
      "progress: 91 0.0065271081402897835\n",
      "\t grad: 1.0 2.0 0.31465959548950195 0.31465959548950195 0.31465959548950195\n",
      "\t grad: 2.0 4.0 -1.7466468811035156 -0.8733234405517578 -0.4366617202758789\n",
      "\t grad: 3.0 6.0 1.4509849548339844 0.4836616516113281 0.16122055053710938\n",
      "progress: 92 0.00649801641702652\n",
      "\t grad: 1.0 2.0 0.31499528884887695 0.31499528884887695 0.31499528884887695\n",
      "\t grad: 2.0 4.0 -1.7440509796142578 -0.8720254898071289 -0.43601274490356445\n",
      "\t grad: 3.0 6.0 1.4478435516357422 0.48261451721191406 0.1608715057373047\n",
      "progress: 93 0.0064699104987084866\n",
      "\t grad: 1.0 2.0 0.3153109550476074 0.3153109550476074 0.3153109550476074\n",
      "\t grad: 2.0 4.0 -1.7415199279785156 -0.8707599639892578 -0.4353799819946289\n",
      "\t grad: 3.0 6.0 1.4447879791259766 0.4815959930419922 0.16053199768066406\n",
      "progress: 94 0.006442630663514137\n",
      "\t grad: 1.0 2.0 0.31560707092285156 0.31560707092285156 0.31560707092285156\n",
      "\t grad: 2.0 4.0 -1.7390518188476562 -0.8695259094238281 -0.43476295471191406\n",
      "\t grad: 3.0 6.0 1.4418182373046875 0.4806060791015625 0.1602020263671875\n",
      "progress: 95 0.006416172254830599\n",
      "\t grad: 1.0 2.0 0.3158855438232422 0.3158855438232422 0.3158855438232422\n",
      "\t grad: 2.0 4.0 -1.7366409301757812 -0.8683204650878906 -0.4341602325439453\n",
      "\t grad: 3.0 6.0 1.4389429092407227 0.4796476364135742 0.1598825454711914\n",
      "progress: 96 0.006390606984496117\n",
      "\t grad: 1.0 2.0 0.3161449432373047 0.3161449432373047 0.3161449432373047\n",
      "\t grad: 2.0 4.0 -1.7342891693115234 -0.8671445846557617 -0.43357229232788086\n",
      "\t grad: 3.0 6.0 1.436136245727539 0.4787120819091797 0.15957069396972656\n",
      "progress: 97 0.0063657015562057495\n",
      "\t grad: 1.0 2.0 0.3163881301879883 0.3163881301879883 0.3163881301879883\n",
      "\t grad: 2.0 4.0 -1.7319889068603516 -0.8659944534301758 -0.4329972267150879\n",
      "\t grad: 3.0 6.0 1.4334239959716797 0.47780799865722656 0.1592693328857422\n",
      "progress: 98 0.0063416799530386925\n",
      "\t grad: 1.0 2.0 0.31661415100097656 0.31661415100097656 0.31661415100097656\n",
      "\t grad: 2.0 4.0 -1.7297439575195312 -0.8648719787597656 -0.4324359893798828\n",
      "\t grad: 3.0 6.0 1.4307546615600586 0.47691822052001953 0.15897274017333984\n",
      "progress: 99 0.00631808303296566\n",
      "predict (after training) 4 8.544171333312988\n"
     ]
    }
   ],
   "source": [
    "print(\"predict (before training)\",4, forward(4).item())\n",
    "for epoch in range(100):\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        l = loss(x, y) \n",
    "        l.backward() \n",
    "        print('\\t grad:', x, y, w1.grad.item(), w2.grad.item(), b.grad.item()) \n",
    "        w1.data = w1.data - 0.01 * w1.grad.data\n",
    "        w2.data = w2.data - 0.01 * w2.grad.data\n",
    "        b.data = b.data - 0.01 * b.grad.data\n",
    "        w1.grad.data.zero_()\n",
    "        w2.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    print(\"progress:\", epoch, l.item())\n",
    "print(\"predict (after training)\", 4, forward(4).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
